<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BIOML Lab | Publications</title>
    <!-- CSS Links etc. -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css"> <!-- Link to the purple theme stylesheet -->
</head>
<body>
    <!-- BIOML Navigation Bar -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top">
        <div class="container">
            <a class="navbar-brand" href="index.html">BIOML</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
                    <li class="nav-item"><a class="nav-link" href="research.html">Research</a></li>
                    <li class="nav-item"><a class="nav-link" href="members.html">People</a></li>
                    <li class="nav-item"><a class="nav-link active" href="publications.html">Publications</a></li>
                    <li class="nav-item"><a class="nav-link" href="contact.html">Contact</a></li>
                </ul>
                <button id="theme-toggle" class="btn theme-toggle-btn ms-2">
                    <i class="fas fa-moon"></i>
                </button>
            </div>
        </div>
    </nav>

    <!-- Main Content -->
    <main>
        <section id="publications" class="section fade-in">
            <div class="container">
                <h2 class="mb-5">Publications & Preprints</h2>

                <!-- Google Scholar Introductory Paragraph -->
                <div class="text-center mb-4">
                    <p class="lead">Below is a curated list of our publications. For a comprehensive and continuously updated list, including citation metrics, please refer to our official Google Scholar profiles (see <strong>People</strong> tab).</p>
                </div>
                <hr>
              
                <!-- Published & Accepted Section -->
                <h3 class="text-center mb-4">Published/Accepted</h3>
                <div class="publications-list mb-5">
                    <!-- AMR-EnsembleNet -->
                    <div class="publication-item">
                        <div class="publication-meta">
                            <span class="pub-type"><i class="fas fa-book"></i> Conference Paper</span>
                            <span class="pub-year"><i class="fas fa-calendar-alt"></i> 2026</span>
                            <span class="pub-status"><i class="fas fa-circle text-info me-2"></i>Accepted</span>
                        </div>
                        <div class="row align-items-center">
                            <div class="col-md-9">
                                <h4>Fusing Sequence Motifs and Pan-Genomic Features: Antimicrobial Resistance Prediction using an Explainable Lightweight 1D CNN - XGBoost Ensemble</h4>
                                <p class="authors"><i class="fas fa-users"></i> M. S. B. Siddiqui, N. Tarannum</p>
                                <p class="venue"><i class="fas fa-university"></i> To appear in <em>2026 SupercomputingAsia / High Performance Computing in Asia-Pacific Region (SCA/HPCAsia)</em></p>
                            </div>
                            <div class="col-md-3 text-md-end">
                                <div class="publication-links">
                                    <button class="btn btn-outline-primary btn-sm" data-bs-toggle="modal" data-bs-target="#abstractModal4"><i class="fas fa-align-left"></i> Abstract</button>
                                    <a href="https://www.biorxiv.org/content/early/2025/09/27/2025.09.27.678993" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt"></i> Paper</a>
                                    <a href="https://github.com/Saiful185/AMR-EnsembleNet" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Under Review / Preprints Section -->
                <h3 class="text-center mb-4">Under Review</h3>
                <div class="publications-list">
                    <!-- S3F-Net -->
                    <div class="publication-item">
                        <div class="publication-meta">
                            <span class="pub-type"><i class="fas fa-book-open"></i> Journal Article</span>
                            <span class="pub-year"><i class="fas fa-calendar-alt"></i> 2025</span>
                            <span class="pub-status"><i class="fas fa-circle text-warning me-2"></i>Under Review</span>
                        </div>
                        <div class="row align-items-center">
                            <div class="col-md-9">
                                <h4>S³F-Net: A Multi-Modal Approach to Medical Image Classification via Spatial-Spectral Summarizer Fusion Network</h4>
                                <p class="authors"><i class="fas fa-users"></i> M. S. B. Siddiqui, M. I. H. Bhuiyan</p>
                                <p class="venue"><i class="fas fa-university"></i> Under review at&nbsp;<em>IEEE Journal of Biomedical and Health Informatics</em></p>
                            </div>
                            <div class="col-md-3 text-md-end">
                                <div class="publication-links">
                                    <button class="btn btn-outline-primary btn-sm" data-bs-toggle="modal" data-bs-target="#abstractModal2"><i class="fas fa-align-left"></i> Abstract</button>
                                    <a href="https://arxiv.org/abs/2509.23442" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt"></i> Preprint</a>
                                    <a href="https://github.com/Saiful185/S3F-Net" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                    <!-- AudioFuse -->
                    <div class="publication-item">
                        <div class="publication-meta">
                            <span class="pub-type"><i class="fas fa-book"></i> Conference Paper</span>
                            <span class="pub-year"><i class="fas fa-calendar-alt"></i> 2025</span>
                            <span class="pub-status"><i class="fas fa-circle text-warning me-2"></i>Under Review</span>
                        </div>
                        <div class="row align-items-center">
                            <div class="col-md-9">
                                <h4>AudioFuse: Unified Spectral-Temporal Learning via a Hybrid ViT-1D CNN Architecture for Robust Phonocardiogram Classification</h4>
                                <p class="authors"><i class="fas fa-users"></i> M. S. B. Siddiqui, U. Saha</p>
                                <p class="venue"><i class="fas fa-university"></i> Under review at&nbsp;<em>2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em></p>
                            </div>
                            <div class="col-md-3 text-md-end">
                                <div class="publication-links">
                                    <button class="btn btn-outline-primary btn-sm" data-bs-toggle="modal" data-bs-target="#abstractModal5"><i class="fas fa-align-left"></i> Abstract</button>
                                    <a href="https://arxiv.org/abs/2509.23454" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fas fa-external-link-alt"></i> Preprint</a>
                                    <a href="https://github.com/Saiful185/AudioFuse" class="btn btn-outline-primary btn-sm" target="_blank"><i class="fab fa-github"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Connect Section (Updated with GitHub) -->
        <section id="connect" class="section fade-in">
             <div class="container">
                <div class="row justify-content-center">
                    <div class="col-lg-8">
                        <div class="insight-card connect text-center">
                            <h4><i class="fas fa-hands-helping me-2"></i>Collaborate With Us</h4>
                            <p>We are always looking for passionate students, researchers, and collaborators. If our work interests you, please get in touch.</p>
                            <div class="social-links">
                                <a href="https://github.com/bioml-lab" class="btn social-btn github" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i> GitHub</a>
                            </div>
                            <div class="contact-info mt-4">
                                <p><i class="fas fa-envelope"></i> <a href="mailto:bioml.bd@gmail.com">bioml.bd@gmail.com</a></p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <!-- =============================================== -->
    <!-- Abstract Modals (Placed at the bottom) -->
    <!-- =============================================== -->
    <!-- S3F-Net Abstract -->
    <div class="modal fade" id="abstractModal2" tabindex="-1">
        <div class="modal-dialog modal-lg modal-dialog-centered">
            <div class="modal-content">
                <div class="modal-header"><h5 class="modal-title">Abstract</h5><button type="button" class="btn-close" data-bs-dismiss="modal"></button></div>
                <div class="modal-body">
                    <p>Convolutional Neural Networks (CNNs) have become a cornerstone of medical image analysis due to their proficiency in learning hierarchical spatial features. However, this focus on a single domain is inefficient at capturing global, holistic patterns and fails to explicitly model an image's frequency-domain characteristics. To address these challenges, we propose the Spatial-Spectral Summarizer Fusion Network (S³F-Net), a dual-branch framework that learns from both spatial and spectral representations simultaneously. The S³F-Net performs a fusion of a deep spatial CNN with our proposed shallow spectral encoder, SpectraNet. SpectraNet features the proposed SpectralFilter layer, which leverages the Convolution Theorem by applying a bank of learnable filters directly to an image's full Fourier spectrum via a computation-efficient element-wise multiplication. This allows the SpectralFilter layer to attain a global receptive field instantaneously, with its output being distilled by a lightweight summarizer network. We evaluate S³F-Net across four diverse medical imaging datasets spanning different scales and modalities: HAM10000 (dermoscopy), BUSI (ultrasound), BRISC2025 (MRI), and Chest X-Ray Pneumonia (radiography), to validate its efficacy and generalizability, and reveal the task-dependent nature of the optimal fusion strategy. Our framework consistently and significantly outperforms its strong spatial-only baseline in all cases, with accuracy improvements of up to 5.13%. With a powerful Bilinear Fusion, S³F-Net achieves a state-of-the-art competitive accuracy of 98.76% on the BRISC2025 dataset. A simpler Concatenation Fusion performs better on the texture-dominant Chest X-Ray Pneumonia dataset, achieving 93.11% accuracy, surpassing many top-performing, much deeper models. Our explainability analysis also reveals that the S³F-Net learns to dynamically adjust its reliance on each branch based on the input pathology. These results verify that our dual-domain approach is a powerful and generalizable paradigm for medical image analysis.</p>
                </div>
            </div>
        </div>
    </div>
    <!-- AMR Abstract -->
    <div class="modal fade" id="abstractModal4" tabindex="-1">
        <div class="modal-dialog modal-lg modal-dialog-centered">
            <div class="modal-content">
                <div class="modal-header"><h5 class="modal-title">Abstract</h5><button type="button" class="btn-close" data-bs-dismiss="modal"></button></div>
                <div class="modal-body">
                    <p>Antimicrobial Resistance (AMR) is a rapidly escalating global health crisis. While genomic sequencing enables rapid prediction of resistance phenotypes, current computational methods have limitations. Standard machine learning models treat the genome as an unordered collection of features, ignoring the sequential context of Single Nucleotide Polymorphisms (SNPs). State-of-the-art sequence models like Transformers are often too data-hungry and computationally expensive for the moderately-sized datasets that are typical in this domain. To address these challenges, we propose AMR-EnsembleNet, an ensemble framework that synergistically combines sequence-based and feature-based learning. We developed a lightweight, custom 1D Convolutional Neural Network (CNN) to efficiently learn predictive sequence motifs from high-dimensional SNP data. This sequence-aware model was ensembled with an XGBoost model, a powerful gradient boosting system adept at capturing complex, non-local feature interactions. We trained and evaluated our framework on a benchmark dataset of 809 E. coli strains, predicting resistance across four antibiotics with varying class imbalance. Our 1D CNN-XGBoost ensemble consistently achieved top-tier performance across all the antibiotics, reaching a Matthews Correlation Coefficient (MCC) of 0.926 for Ciprofloxacin (CIP) and the highest Macro F1-score of 0.691 for the challenging Gentamicin (GEN) AMR prediction. We also show that our model consistently focuses on SNPs within well-known AMR genes like fusA and parC, confirming it learns the correct genetic signals for resistance. Our work demonstrates that fusing a sequence-aware 1D CNN with a feature-based XGBoost model creates a powerful ensemble, overcoming the limitations of using either an order-agnostic or a standalone sequence model.</p>
                </div>
            </div>
        </div>
    </div>
    <!-- AudioFuse Abstract -->
    <div class="modal fade" id="abstractModal5" tabindex="-1">
        <div class="modal-dialog modal-lg modal-dialog-centered">
            <div class="modal-content">
                <div class="modal-header"><h5 class="modal-title">Abstract</h5><button type="button" class="btn-close" data-bs-dismiss="modal"></button></div>
                <div class="modal-body">
                    <p>Biomedical audio signals, such as phonocardiograms (PCG), are inherently rhythmic and contain diagnostic information in both their spectral (tonal) and temporal domains. Standard 2D spectrograms provide rich spectral features but compromise the phase information and temporal precision of the 1D waveform. We propose AudioFuse, an architecture that simultaneously learns from both complementary representations to classify PCGs. To mitigate the overfitting risk common in fusion models, we integrate a custom, wide-and-shallow Vision Transformer (ViT) for spectrograms with a shallow 1D CNN for raw waveforms. On the PhysioNet 2016 dataset, AudioFuse achieves a state-of-the-art competitive ROC-AUC of 0.8608 when trained from scratch, outperforming its spectrogram (0.8066) and waveform (0.8223) baselines. Moreover, it demonstrates superior robustness to domain shift on the challenging PASCAL dataset, maintaining an ROC-AUC of 0.7181 while the spectrogram baseline collapses (0.4873). Fusing complementary representations thus provides a strong inductive bias, enabling the creation of efficient, generalizable classifiers without requiring large-scale pre-training.</p>
                </div>
            </div>
        </div>
    </div>
    
    <!-- Footer -->
    <footer class="text-center">
        <div class="container">
            <p>&copy; 2025 BIOML Lab. All rights reserved.</p>
        </div>
    </footer>

    <!-- JS Scripts with Dark Mode -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <script>
        // Fade-in animation script
        const fadeElements = document.querySelectorAll('.fade-in');
        const observer = new IntersectionObserver(entries => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                }
            });
        });
        fadeElements.forEach(element => {
            observer.observe(element);
        });

        // Dark mode toggle script
        const themeToggle = document.getElementById('theme-toggle');
        const body = document.body;
        const icon = themeToggle.querySelector('i');
        const applyTheme = () => {
            const savedTheme = localStorage.getItem('theme');
            if (savedTheme === 'dark') {
                body.classList.add('dark-mode');
                icon.className = 'fas fa-sun';
            } else {
                body.classList.remove('dark-mode');
                icon.className = 'fas fa-moon';
            }
        };
        themeToggle.addEventListener('click', () => {
            body.classList.toggle('dark-mode');
            if (body.classList.contains('dark-mode')) {
                localStorage.setItem('theme', 'dark');
                icon.className = 'fas fa-sun';
            } else {
                localStorage.setItem('theme', 'light');
                icon.className = 'fas fa-moon';
            }
        });
        document.addEventListener('DOMContentLoaded', applyTheme);
    </script>
</body>
</html>
